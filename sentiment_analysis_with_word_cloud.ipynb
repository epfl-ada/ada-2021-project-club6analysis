{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cf6065",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb309d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "from tqdm import tqdm\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from PIL import Image\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f362e",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Part 1: Creating the sentiment dataframe\n",
    "First we are extracting the apple data from the already filtered csv-files. These were created using the Extraction_of_relevant_apple_data.ipynb jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f75a05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/quotes-2020-apple-filter.csv\",sep=\";\")\n",
    "df = df.append(pd.read_csv(\"data/quotes-2019-apple-filter.csv\",sep=\";\"))\n",
    "df = df.append(pd.read_csv(\"data/quotes-2018-apple-filter.csv\",sep=\";\"))\n",
    "df = df.append(pd.read_csv(\"data/quotes-2017-apple-filter.csv\",sep=\";\"))\n",
    "df = df.append(pd.read_csv(\"data/quotes-2016-apple-filter.csv\",sep=\";\"))\n",
    "df = df.append(pd.read_csv(\"data/quotes-2015-apple-filter.csv\",sep=\";\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9348b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0082795",
   "metadata": {},
   "source": [
    "Changing the dataframe columns to their appropriate data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb7fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.quoteID = df.quoteID.astype('string')\n",
    "df.quotation = df.quotation.astype('string')\n",
    "df.speaker = df.speaker.astype('string')\n",
    "df.numOccurrences = df.numOccurrences.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2e200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582094ca",
   "metadata": {},
   "source": [
    "Sorting the dataframe by date so we get the correct order of the dataframes for the sentiment graph that will be created later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82defb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('date')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67db4444",
   "metadata": {},
   "source": [
    "For each row in the dataframe we will attach 4 new columns, neg, neu, pos and compound. These values are the negative, neutral, positive and compound values we get from the SentimentIntensityAnalyzer polary scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba615ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['quoteID', 'quotation', 'speaker', 'date', 'numOccurrences','neg', 'neu', 'pos', 'compound']\n",
    "    \n",
    "sentiment_info_df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "print(\"Total number of rows: \", df.shape[0])\n",
    "for idx, row in tqdm(df.iterrows()):\n",
    "    \n",
    "    # Calculating scores from SentimentIntensityAnalyzer\n",
    "    new_row_dct = SentimentIntensityAnalyzer().polarity_scores(row['quotation'])\n",
    "    \n",
    "    # Creating and writing over value    \n",
    "    new_row_dct['quoteID'] = row['quoteID']\n",
    "    new_row_dct['quotation'] = row['quotation']\n",
    "    new_row_dct['speaker'] = row['speaker']\n",
    "    new_row_dct['date'] = row['date']\n",
    "    new_row_dct['numOccurrences'] = row['numOccurrences']\n",
    "    new_row = pd.DataFrame(new_row_dct, columns=column_names, index=[0])\n",
    "    sentiment_info_df = sentiment_info_df.append(new_row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0d660e",
   "metadata": {},
   "source": [
    "We will also attach a date_clean column to the dataframe which only contains the date and not the timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e274f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by datetime\n",
    "sentiment_info_df_sorted = sentiment_info_df.set_index('quoteID').sort_values('date')\n",
    "\n",
    "# Clean the date column, such that it only contains date information and not timestamp\n",
    "sentiment_info_df_sorted['date_clean'] = sentiment_info_df_sorted.apply(lambda x: x['date'][:10],axis=1)\n",
    "sentiment_info_df_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0eca74",
   "metadata": {},
   "source": [
    "We will save the current dataframe to csv since the analysis part takes around 20 minutes, so we don't have to redo that part each time we are going to change something in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f83c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment_info_df_sorted.to_csv('./data/sentiment_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c69db5",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Part 2: Sentiment analysis\n",
    "Here we firstly read the dataframe from the csv and remove the fortnite outlier quote, which contains 39 978 occurences. This quote was decided to be removed in the exploratory part of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d86ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from csv to recreate a the fresh dataframe\n",
    "sentiment_df = pd.read_csv('./data/sentiment_df.csv')\n",
    "#finding index of outlier\n",
    "print(sentiment_df[sentiment_df.numOccurrences == 39978])\n",
    "#removing outlier\n",
    "sentiment_df = sentiment_df.drop(58674)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d4ae07",
   "metadata": {},
   "source": [
    "**Raw datapoints visualized:**  \n",
    "Firstly we will visualize the datapoints for positive and negative tweets.\n",
    "- Green points: positive tweets\n",
    "- Red points: negative tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dd665f",
   "metadata": {},
   "source": [
    "This visualization is mainly to get a feeling of how to points are distributed, but it won't give us a lot of information straight away. It is just too much information for a human being to interpret, we will therefore make an aggregated graph based on the positive and negative points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc43d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(25,10))\n",
    "\n",
    "cutoff_decimal = 0.0\n",
    "\n",
    "\n",
    "pos_scores_df = sentiment_df[sentiment_df['compound'] > cutoff_decimal]\n",
    "pos_scores = pos_scores_df['compound']\n",
    "pos_dates = pos_scores_df['date_clean']\n",
    "\n",
    "neg_scores_df = sentiment_df[sentiment_df['compound'] < -cutoff_decimal]\n",
    "neg_scores = -neg_scores_df['compound']\n",
    "neg_dates = neg_scores_df['date_clean']\n",
    "ax.set_ylim([0.0,1])\n",
    "ax.scatter(pos_dates, pos_scores, s=5, color='green')\n",
    "ax.scatter(neg_dates, neg_scores, s=5, color='red')\n",
    "\n",
    "loc = plticker.MultipleLocator(base=50) # this locator puts ticks at regular intervals\n",
    "ax.xaxis.set_major_locator(loc)\n",
    "plt.title('Visualizing all sentiment intensity scores', fontsize=18)\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Sentiment intensity scores for each tweet in dataset', fontsize=17)\n",
    "ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69484034",
   "metadata": {},
   "source": [
    "## 1 month aggregated sentiment intensity scores\n",
    "\n",
    "Positive tweets will account for their value (given from SentimentIntensityAnalyzer) times +1 and times numOccurences.  \n",
    "Negative tweets will account for their value (given from SentimentIntensityAnalyzer) times -1 and times numOccurences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b673df",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_month_sentiment = []\n",
    "agg_month_dates = []\n",
    "\n",
    "for index, (idx, row) in enumerate(sentiment_df.iterrows()):\n",
    "    date = row['date_clean']\n",
    "    if index == 0:\n",
    "        current_month = date[:7]\n",
    "        current_size = 0\n",
    "\n",
    "\n",
    "    tmp_month = current_month\n",
    "    current_month = date[:7] # the seven first digits of the date\n",
    "    if tmp_month != current_month:\n",
    "        agg_month_sentiment.append(current_size)\n",
    "        current_size = 0\n",
    "        agg_month_dates.append(current_month)\n",
    "    \n",
    "    # updates weighted aggregated value of positive and negative\n",
    "    \n",
    "    current_size += row['compound']*row['numOccurrences']\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf41832e",
   "metadata": {},
   "source": [
    "**For the datastory:**\n",
    "For our sentiment analysis, we have labeled every quote in our apple dataset with a sentiment compound score between -1.0 and 1.0. Since there are too many quotes to represent visually, we have aggregated quote scores for each month and visualized the aggregated score for that month. These calculations heavily depend on the sentiment tool, so to secure that we don't include neutral quotes or quotes that the tool is hesitant about, we have made an arbitrarily cutoff of 0.6. Therefore, the graph will not include sentiment intensity scores between -0.6 and 0.6 in the calculations.\n",
    "\n",
    "Comments on the graph: As we can see by the chart there seems to be a disproportionate balance between positive and negative quotes since most months, the aggregated score is far above 0. We can also see a reduction in sentiment intensity scores from late 2019 until early 2020 - which may be caused by covid-19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6a2e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1,ax_1 = plt.subplots(figsize=(18,8))\n",
    "result_values = []\n",
    "result_mon = []\n",
    "for mon, agg in zip(agg_month_dates, agg_month_sentiment):\n",
    "    result_values.append(agg)\n",
    "    result_mon.append(mon)\n",
    "\n",
    "sns.set_theme(style=\"ticks\", rc={\"axes.spines.right\": False, \"axes.spines.top\": False},\n",
    "              font_scale=1.8, font=\"PT Sans\")\n",
    "\n",
    "\n",
    "ax_1.plot(result_mon, result_values, '-o', color='#800020')\n",
    "#plt.title('1 month aggregation scores for tweets', fontsize=18)\n",
    "plt.xlabel('Date', fontsize=24)\n",
    "plt.ylabel('Aggregated sentiment intensity score', fontsize=24)\n",
    "\n",
    "#ax_1.plot(agg_month_dates, agg_month_sentiment)\n",
    "plt.xticks(rotation=45);\n",
    "for n, label in enumerate(ax_1.xaxis.get_ticklabels()):\n",
    "    if n % 12 != 0:\n",
    "        label.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26808290",
   "metadata": {},
   "source": [
    "## 1 month aggregated and weighted sentiment intensity scores (based on speaker)\n",
    "**Name list - multiplicative weight:**\n",
    "1. Tim Cook  - 2.0\n",
    "2. Steve Jobs - 1.9\n",
    "3. Eddy Cue - 1.8\n",
    "4. Jony Ive - 1.7\n",
    "5. Donald Trump - 1.6\n",
    "6. Phill Schiller - 1.5\n",
    "7. Jeff Williams - 1.4\n",
    "8. Steve Wozniak - 1.3\n",
    "9. Ben Wood  -  1.2\n",
    "10. Brian White  - 1.1\n",
    "\n",
    "Based on our \"Most frequently quoted speakers about Apple\" bar chart race, we will give quotes that has a speaker to any of the people from the top 10 list some additional weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3859745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_weights = {\n",
    "    \"Tim Cook\": 2,\n",
    "    \"Steve Jobs\": 1.9,\n",
    "     \"Eddy Cue\" : 1.8,\n",
    "     \"Jony Ive\" : 1.7,\n",
    "     \"Donald Trump\" : 1.6,\n",
    "     \"Phill Schiller\" : 1.5,\n",
    "     \"Jeff Williams\" : 1.4,\n",
    "     \"Steve Wozniak\" : 1.3,\n",
    "     \"Ben Wood\" : 1.2,\n",
    "     \"Brian White\" : 1.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed67962",
   "metadata": {},
   "source": [
    "In this code block we do the same as we did in the one above, the only difference is that we scale the datapoint if it is included in the speaker weights dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f1583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_month_speaker_weight_sentiment = []\n",
    "agg_month_speaker_weight_dates = []\n",
    "\n",
    "for index, (idx, row) in enumerate(sentiment_df.iterrows()):\n",
    "    date = row['date_clean']\n",
    "    speaker = row['speaker']\n",
    "    if index == 0:\n",
    "        current_speaker_weight_month = date[:7]\n",
    "        current_speaker_weight_size = 0\n",
    "\n",
    "\n",
    "    tmp_speaker_weight_month = current_speaker_weight_month\n",
    "    current_speaker_weight_month = date[:7] # the seven first digits of the date\n",
    "    if tmp_speaker_weight_month != current_speaker_weight_month:\n",
    "        agg_month_speaker_weight_sentiment.append(current_speaker_weight_size)\n",
    "        current_speaker_weight_size = 0\n",
    "        agg_month_speaker_weight_dates.append(current_speaker_weight_month)\n",
    "    \n",
    "    speaker_mult = 1\n",
    "    if speaker in speaker_weights:\n",
    "        speaker_mult = speaker_weights[speaker]\n",
    "        \n",
    "    # updates weighted aggregated value of positive and negative\n",
    "    if abs(row['compound']) > 0.6:\n",
    "        current_speaker_weight_size += row['compound']*row['numOccurrences']*speaker_mult\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41c3afb",
   "metadata": {},
   "source": [
    "Here we have the 1 month aggregations scores which are multiplied by the speaker weights, which gives extra weight to the important speakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8a8275",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_2,ax_2 = plt.subplots(figsize=(18,8))\n",
    "result_values = []\n",
    "result_mon = []\n",
    "for mon, agg in zip(agg_month_speaker_weight_dates, agg_month_speaker_weight_sentiment):\n",
    "    result_values.append(agg)\n",
    "    result_mon.append(mon)\n",
    "\n",
    "        \n",
    "\n",
    "ax_2.scatter(result_mon, result_values)\n",
    "\n",
    "ax_2.plot(result_mon, result_values, '-o', color='green')\n",
    "plt.title('1 month aggregation scores for tweets with additional speaker weights', fontsize=18)\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Aggregated sentiment intensity score', fontsize=18)\n",
    "\n",
    "#ax.plot(agg_month_dates, agg_month_sentiment)\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ca8f98",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 1 week aggregated sentiment intensity scores\n",
    "In this graph we will aggregate on each week, i.e. every 7 day we will make a data point on the graph. It is calculated counting one for each time the days change, when i reaches seven we \"submit\" the aggregated scores to the agg_week_sentiment list, which we will use for plotting. This way we get the aggregated scores for a 7 day period i.e. a week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7337e85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_week_sentiment_weekly = []\n",
    "agg_week_dates_weekly = []\n",
    "day_counter_weekly = 0\n",
    "for index, (idx, row) in enumerate(sentiment_df.iterrows()):\n",
    "    date = row['date_clean']\n",
    "    if index == 0:\n",
    "        current_day_weekly = date[:10]\n",
    "        current_size_weekly = 0\n",
    "\n",
    "\n",
    "    tmp_day_weekly = current_day_weekly\n",
    "    current_day_weekly = date[:10] # the seven first digits of the date\n",
    "    if tmp_day_weekly != current_day_weekly:\n",
    "        day_counter_weekly += 1\n",
    "    if day_counter_weekly == 7:\n",
    "        agg_week_sentiment_weekly.append(current_size_weekly)\n",
    "        agg_week_dates_weekly.append(current_day_weekly)\n",
    "        current_size_weekly = 0\n",
    "        day_counter_weekly = 0\n",
    "\n",
    "    # updates weighted aggregated value of positive and negative\n",
    "    current_size_weekly += row['compound']*row['numOccurrences']\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab3cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_3,ax_3 = plt.subplots(figsize=(18,8))\n",
    "result_week_values = []\n",
    "result_week = []\n",
    "for week, agg in zip(agg_week_dates_weekly, agg_week_sentiment_weekly):\n",
    "    result_week_values.append(agg)\n",
    "    result_week.append(week)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "ax_3.plot(result_week, result_week_values, color='green')\n",
    "loc_weekly = plticker.MultipleLocator(base=5) # this locator puts ticks at regular intervals\n",
    "ax_3.xaxis.set_major_locator(loc_weekly)\n",
    "plt.title('1 week aggregation scores for tweets with additional speaker weights', fontsize=18)\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Aggregated sentiment intensity score', fontsize=18)\n",
    "\n",
    "#ax.plot(agg_month_dates, agg_month_sentiment)\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d190001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b08bb7d",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 1 day aggregated sentiment intensity scores\n",
    "In this graph we will aggregated quotes from each day, i.e. every unique day we will make a data point on the graph. It is calculated by \"submitting\" the scores every time the day changes in dateframe. This way we get the aggregated scores for each unique day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ca8aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a5222",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_sentiment_daily = []\n",
    "agg_dates_daily = []\n",
    "\n",
    "for index, (idx, row) in enumerate(sentiment_df.iterrows()):\n",
    "    date = row['date_clean']\n",
    "    if index == 0:\n",
    "        current_day_daily = date[:10]\n",
    "        current_size_daily = 0\n",
    "\n",
    "\n",
    "    tmp_day_daily = current_day_daily\n",
    "    current_day_daily = date[:10] # the seven first digits of the date\n",
    "    if tmp_day_daily != current_day_daily:\n",
    "        agg_sentiment_daily.append(current_size_daily)\n",
    "        current_size_daily = 0\n",
    "        agg_dates_daily.append(current_day_daily)\n",
    "\n",
    "    # updates weighted aggregated value of positive and negative\n",
    "    current_size_daily += row['compound']*row['numOccurrences']\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4c251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_4,ax_4 = plt.subplots(figsize=(18,8))\n",
    "result_daily_values = []\n",
    "result_daily = []\n",
    "for day, agg in zip(agg_dates_daily, agg_sentiment_daily):\n",
    "    result_daily_values.append(agg)\n",
    "    result_daily.append(day)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "ax_4.plot(result_daily, result_daily_values, color='green')\n",
    "loc_daily = plticker.MultipleLocator(base=30) # this locator puts ticks at regular intervals\n",
    "ax_4.xaxis.set_major_locator(loc_daily)\n",
    "plt.title('1 day aggregation scores for tweets with additional speaker weights', fontsize=18)\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Aggregated sentiment intensity score', fontsize=18)\n",
    "\n",
    "#ax.plot(agg_month_dates, agg_month_sentiment)\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c346b9",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "# Word clouds\n",
    "In this section we will look at the word clouds for a positive and negative quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e42bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_quotation_text = \"\"\n",
    "\n",
    "for index, (idx, row) in tqdm(enumerate(sentiment_df.iterrows())):\n",
    "\n",
    "    all_quotation_text += \" \" + row['quotation']\n",
    "\n",
    "        \n",
    "for string in ['Apple', 'apple', 'iPad', 'iPhone', 'Apple watch', 'apples', 'Apples', 'iPhones', ' S ', ' s ']:\n",
    "    all_quotation_text = all_quotation_text.replace(string, \"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438f1518",
   "metadata": {},
   "source": [
    "**Removing words that are products:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c233433",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(STOPWORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db4af65",
   "metadata": {},
   "source": [
    "## Word cloud for positive quotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cf379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array(Image.open(\"./data/apple_logo.png\"))\n",
    "\n",
    "\n",
    "word_cloud = WordCloud(stopwords=stopwords, background_color=\"white\", mask=mask, mode=\"RGBA\", max_words=500)\n",
    "wc_all_quotes = word_cloud.generate(all_quotation_text)\n",
    "plt.figure()\n",
    "image_colors = ImageColorGenerator(mask)\n",
    "plt.figure(figsize=[20,20])\n",
    "plt.imshow(wc_all_quotes.recolor(color_func=image_colors), interpolation='bilinear')\n",
    "plt.axis(\"off\");\n",
    "plt.savefig(\"./data/apple_word_cloud.png\", format=\"png\") \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df5c62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
